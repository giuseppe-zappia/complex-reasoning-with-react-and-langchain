{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a8769ba-5cdb-4e55-84b9-e3fa0f7e8cac",
   "metadata": {},
   "source": [
    "# Enabling Complex Reasoning and Action with ReAct, LLMs, and LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fdda37-63cb-4a61-89ec-0b7900ae83d2",
   "metadata": {},
   "source": [
    "**NOTEBOOK KERNEL REQUIREMENTS** \n",
    "\n",
    "Please ensure you are using the following settings for your notebook environment. \n",
    "\n",
    "![notebook-environment](notebook-environment.png)\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook you will learn how to use multiple different techniques and models to build a ReAct based framework. ReAct is an approach to problem solving with large language models based on 2 main premises: Reasoning and Action. With ReAct, you combine reasoning, through chain-of-thought, with the ability to perform actions through a set of tools. This enables the model to (Re)ason through the input request to determine what steps need to be performed, and uses the available tools to perform (ACT)ions as part of a step-by-step resolution.\n",
    "\n",
    "More details on ReAct can be found in this research paper: [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629) and the [Google AI Blog](https://blog.research.google/2022/11/react-synergizing-reasoning-and-acting.html)\n",
    "\n",
    "![image.png](ReAct-Diagram.png)\n",
    "\n",
    "Image taken from Google AI Blog\n",
    "\n",
    "To demonstrate the potential of ReAct this notebook will focus on a use case involving and Insurance Bot.  For demonstration purposes, this Bot is designed to handle insurance policy requests and is provided a set of tools, including a SQLLite database and an insurance processing API, to accept requests on input, reason through the steps needed to carry out the request, and carry out the actions required.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c9b99-de64-4829-ba40-079b58721faa",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a11660-abf0-44ff-b0d9-e91a36ca95f1",
   "metadata": {},
   "source": [
    "As part of this workshop you will run a local, quantized version of Meta's LLaMa-2-13B. In order do do this you will need llama-cpp-python, which requires a local compiler. This will install `g++` and set it as the default so that you can install llama-cpp-python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e175814d-9741-49cb-aef3-f7a87720d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit:1 http://security.debian.org/debian-security bullseye-security InRelease\n",
      "Hit:2 http://deb.debian.org/debian bullseye InRelease\n",
      "Get:3 http://deb.debian.org/debian bullseye-updates InRelease [44.1 kB]\n",
      "Fetched 44.1 kB in 0s (181 kB/s)    \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "g++ is already the newest version (4:10.2.1-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n",
      "env: CXX=g++\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get -y install g++\n",
    "%env CXX=g++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e030aa9a-3e86-47a9-a031-928e51ebfe34",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets==8.1.1 in /opt/conda/lib/python3.10/site-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets==8.1.1) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets==8.1.1) (8.16.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.10/site-packages (from ipywidgets==8.1.1) (5.11.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/conda/lib/python3.10/site-packages (from ipywidgets==8.1.1) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/conda/lib/python3.10/site-packages (from ipywidgets==8.1.1) (3.0.9)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets==8.1.1) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.1.1) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.1.1) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets==8.1.1) (0.2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.1) (2.0.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.1) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.1.1) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets==8.1.1) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers[torch]==4.34.1 in /opt/conda/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.34.1) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.34.1) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.34.1) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.34.1) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from transformers[torch]==4.34.1) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.34.1) (2022.7.9)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.34.1) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.34.1) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.34.1) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.34.1) (4.64.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.34.1) (2.1.0)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]==4.34.1) (0.24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers[torch]==4.34.1) (5.9.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]==4.34.1) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]==4.34.1) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]==4.34.1) (3.0.9)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (12.3.52)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]==4.34.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]==4.34.1) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]==4.34.1) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]==4.34.1) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]==4.34.1) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence_transformers==2.2.2 in /opt/conda/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (4.34.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.16.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.0.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.11.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (3.7)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.17.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.6.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2022.7.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (21.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers==2.2.2) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence_transformers==2.2.2) (12.3.52)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (0.4.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers==2.2.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers==2.2.2) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers==2.2.2) (10.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers==2.2.2) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence_transformers==2.2.2) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain==0.0.324 in /opt/conda/lib/python3.10/site-packages (0.0.324)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from langchain==0.0.324) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.324) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.324) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.324) (3.5.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.324) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.324) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.324) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.324) (0.0.54)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.324) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.324) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.324) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.324) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.324) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.324) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.324) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.324) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.324) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.324) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.324) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.324) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.324) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.324) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.324) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.0.324) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.0.324) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain==0.0.324) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.324) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain==0.0.324) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.324) (1.1.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.324) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.324) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.324) (3.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: llama-cpp-python==0.2.11 in /opt/conda/lib/python3.10/site-packages (0.2.11)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python==0.2.11) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python==0.2.11) (1.26.0)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /opt/conda/lib/python3.10/site-packages (from llama-cpp-python==0.2.11) (5.6.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: faiss-cpu==1.7.4 in /opt/conda/lib/python3.10/site-packages (1.7.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-experimental==0.0.36 in /opt/conda/lib/python3.10/site-packages (0.0.36)\n",
      "Requirement already satisfied: langchain>=0.0.308 in /opt/conda/lib/python3.10/site-packages (from langchain-experimental==0.0.36) (0.0.324)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from langchain>=0.0.308->langchain-experimental==0.0.36) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain-experimental==0.0.36) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain-experimental==0.0.36) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain-experimental==0.0.36) (3.5.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain-experimental==0.0.36) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain-experimental==0.0.36) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain-experimental==0.0.36) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain-experimental==0.0.36) (0.0.54)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain-experimental==0.0.36) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain-experimental==0.0.36) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain-experimental==0.0.36) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain>=0.0.308->langchain-experimental==0.0.36) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental==0.0.36) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental==0.0.36) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental==0.0.36) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental==0.0.36) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental==0.0.36) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.308->langchain-experimental==0.0.36) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain>=0.0.308->langchain-experimental==0.0.36) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain>=0.0.308->langchain-experimental==0.0.36) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental==0.0.36) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental==0.0.36) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain>=0.0.308->langchain-experimental==0.0.36) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain-experimental==0.0.36) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain-experimental==0.0.36) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain>=0.0.308->langchain-experimental==0.0.36) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.0.308->langchain-experimental==0.0.36) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.0.308->langchain-experimental==0.0.36) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.308->langchain-experimental==0.0.36) (1.1.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental==0.0.36) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental==0.0.36) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.308->langchain-experimental==0.0.36) (3.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sqlalchemy==1.4.39 in /opt/conda/lib/python3.10/site-packages (1.4.39)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy==1.4.39) (1.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets==8.1.1\n",
    "%pip install transformers[torch]==4.34.1\n",
    "%pip install sentence_transformers==2.2.2\n",
    "%pip install langchain==0.0.324\n",
    "%pip install llama-cpp-python==0.2.11\n",
    "%pip install faiss-cpu==1.7.4\n",
    "%pip install langchain-experimental==0.0.36\n",
    "%pip install sqlalchemy==1.4.39"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2263d-b376-4aee-a4b5-6962891d9b7b",
   "metadata": {},
   "source": [
    "# Workshop Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06870628-2f15-4da1-84fd-2464ac913a42",
   "metadata": {
    "tags": []
   },
   "source": [
    "Setting `langchain.debug = True` allows you to see the deep dive internals of what is happening under the hood of your chains and agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7229813-f772-4e85-80bb-9a060d1d857e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a0e591-2f09-415f-8732-45cbbbe6c8a8",
   "metadata": {},
   "source": [
    "## Setup sample data using SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f981bd-9e1e-4300-88c7-b321c2ec8639",
   "metadata": {
    "tags": []
   },
   "source": [
    "As part of this workshop, you will see how to work with a variety of different tool types to retrieve and act on data.\n",
    "\n",
    "Here you will create an in-memory SQLite database to store some sample data for the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f39b8f-0aa9-4600-9bf2-553dcca45d59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData\n",
    "\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5440ac-1da0-4f5c-b321-b5c3102030f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Build out a table of insurance policies. This would typically be normalized, but for simplicity's sake of this example, the policies and users are all in 1 table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c276bfd9-e896-4574-826b-be13cbfd1340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, Table, Date\n",
    "\n",
    "policies = Table(\n",
    "    \"policies\",\n",
    "    metadata_obj,\n",
    "    Column(\"policy_id\", Integer, primary_key=True),\n",
    "    Column(\"first_name\", String(50), nullable=False),\n",
    "    Column(\"last_name\", String(50), nullable=False),\n",
    "    Column(\"phone\", String(15), nullable=False),\n",
    "    Column(\"policy_type\", String(25), nullable=False),\n",
    "    Column(\"policy_date\", Date, nullable=False),\n",
    "    Column(\"policy_value\", Integer, nullable=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47fef6d-d9f1-4004-890d-f85533b39fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f154acc-50c3-4d02-9798-8a7c9304d8d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Generate some some dummy data and insert it into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79677473-6862-4545-b774-efd8cb62f606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#policy data: policy_id, first_name, last_name, phone, policy_type, policy_date, policy_value\n",
    "\n",
    "policy_data = [\n",
    "    [48918, 'Ernest', 'Mcneil', '349-711-8757', 'home', datetime(2023, 1, 1), 250000],\n",
    "    [66958, 'Brian', 'Patel', '368-889-1742', 'auto', datetime(2023, 1, 2), 32000],\n",
    "    [21947, 'Bertram', 'Mcgee', '798-641-5925', 'home', datetime(2023, 1, 3), 550000],\n",
    "    [17108, 'Margarito', 'Rollins', '348-321-5711', 'auto', datetime(2023, 1, 4), 75000],\n",
    "    [98362, 'Miriam', 'Sutton', '361-863-4332', 'auto', datetime(2023, 1, 8), 21000],\n",
    "    [17565, 'Charmaine', 'Hopkins', '206-566-6359', 'home', datetime(2023, 1, 2), 135000],\n",
    "    [10157, 'Jewel', 'Ingram', '598-338-6133', 'home', datetime(2023, 1, 6), 750000],\n",
    "    [33372, 'Kaye', 'Underwood', '555-720-3848', 'home', datetime(2023, 1, 1), 235000],\n",
    "    [97143, 'Josiah', 'Vazquez', '211-391-1757', 'auto', datetime(2023, 1, 5), 17250],\n",
    "    [54621, 'Charles', 'Wise', '502-236-0425', 'home', datetime(2023, 1, 4), 1592000],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "517c127a-5bcf-4252-bbf6-9f7c993f7793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "def insert_policy_data(policy_data_arr):\n",
    "    stmt = insert(policies).values(\n",
    "    policy_id=policy_data_arr[0],\n",
    "    first_name=policy_data_arr[1],\n",
    "    last_name=policy_data_arr[2],\n",
    "    phone=policy_data_arr[3],\n",
    "    policy_type=policy_data_arr[4],\n",
    "    policy_date=policy_data_arr[5],\n",
    "    policy_value=policy_data_arr[6]\n",
    "    )\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70e78b6e-209d-4cc9-884e-2b6f7a362e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48918, 'Ernest', 'Mcneil', '349-711-8757', 'home', datetime.datetime(2023, 1, 1, 0, 0), 250000]\n",
      "[66958, 'Brian', 'Patel', '368-889-1742', 'auto', datetime.datetime(2023, 1, 2, 0, 0), 32000]\n",
      "[21947, 'Bertram', 'Mcgee', '798-641-5925', 'home', datetime.datetime(2023, 1, 3, 0, 0), 550000]\n",
      "[17108, 'Margarito', 'Rollins', '348-321-5711', 'auto', datetime.datetime(2023, 1, 4, 0, 0), 75000]\n",
      "[98362, 'Miriam', 'Sutton', '361-863-4332', 'auto', datetime.datetime(2023, 1, 8, 0, 0), 21000]\n",
      "[17565, 'Charmaine', 'Hopkins', '206-566-6359', 'home', datetime.datetime(2023, 1, 2, 0, 0), 135000]\n",
      "[10157, 'Jewel', 'Ingram', '598-338-6133', 'home', datetime.datetime(2023, 1, 6, 0, 0), 750000]\n",
      "[33372, 'Kaye', 'Underwood', '555-720-3848', 'home', datetime.datetime(2023, 1, 1, 0, 0), 235000]\n",
      "[97143, 'Josiah', 'Vazquez', '211-391-1757', 'auto', datetime.datetime(2023, 1, 5, 0, 0), 17250]\n",
      "[54621, 'Charles', 'Wise', '502-236-0425', 'home', datetime.datetime(2023, 1, 4, 0, 0), 1592000]\n"
     ]
    }
   ],
   "source": [
    "for policy in policy_data:\n",
    "    print(policy)\n",
    "    insert_policy_data(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532aee6-46a0-4e6c-a9a7-475791759987",
   "metadata": {},
   "source": [
    "Quick query over the database to show all the rows, sorted by last name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "215333c8-cdb0-4a08-88e2-ea4aa6e8184a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT policies.policy_id, policies.first_name, policies.last_name, policies.phone, policies.policy_type, policies.policy_date, policies.policy_value \n",
      "FROM policies ORDER BY policies.last_name\n",
      "\n",
      "(17565, 'Charmaine', 'Hopkins', '206-566-6359', 'home', datetime.date(2023, 1, 2), 135000)\n",
      "(10157, 'Jewel', 'Ingram', '598-338-6133', 'home', datetime.date(2023, 1, 6), 750000)\n",
      "(21947, 'Bertram', 'Mcgee', '798-641-5925', 'home', datetime.date(2023, 1, 3), 550000)\n",
      "(48918, 'Ernest', 'Mcneil', '349-711-8757', 'home', datetime.date(2023, 1, 1), 250000)\n",
      "(66958, 'Brian', 'Patel', '368-889-1742', 'auto', datetime.date(2023, 1, 2), 32000)\n",
      "(17108, 'Margarito', 'Rollins', '348-321-5711', 'auto', datetime.date(2023, 1, 4), 75000)\n",
      "(98362, 'Miriam', 'Sutton', '361-863-4332', 'auto', datetime.date(2023, 1, 8), 21000)\n",
      "(33372, 'Kaye', 'Underwood', '555-720-3848', 'home', datetime.date(2023, 1, 1), 235000)\n",
      "(97143, 'Josiah', 'Vazquez', '211-391-1757', 'auto', datetime.date(2023, 1, 5), 17250)\n",
      "(54621, 'Charles', 'Wise', '502-236-0425', 'home', datetime.date(2023, 1, 4), 1592000)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import select\n",
    "\n",
    "stmt = select(policies).order_by(policies.c.last_name)\n",
    "print(f'{stmt}\\n')\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    for row in conn.execute(stmt):\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbeb56d-4506-4a28-84a5-2860b77ab283",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a mock API using Amazon API Gateway\n",
    "\n",
    "Next, we want our LLM to be able to carry out actions using an API that we will provide.  \n",
    "\n",
    "Using the Insurance Bot example, let's create a mock REST API using Amazon API Gateway.  \n",
    "\n",
    "This API will have PUT and DELETE methods, to accept requests to modify or cancel an insurance policy. The API takes  an input request and returns a successful response.  Our API isn't backed by any functional logic for simplicity in the workshop environment.  However, a real implementation would be backed by a fully functional API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cbd8fd2-5deb-406d-a86f-e4d45fae7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "apigateway = boto3.client('apigateway')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49575b7a-88ae-4241-ac04-77783dabb9ea",
   "metadata": {},
   "source": [
    "First, create the rest API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a1ac6f-6018-4c48-8b87-eaa4edb919f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '092cf6fb-9b6b-4735-8662-8b3fb8b679df', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 02:56:55 GMT', 'content-type': 'application/json', 'content-length': '301', 'connection': 'keep-alive', 'x-amzn-requestid': '092cf6fb-9b6b-4735-8662-8b3fb8b679df', 'x-amz-apigw-id': 'NsqyqJuLPHcEbzg='}, 'RetryAttempts': 0}, 'id': 'pqraih5vog', 'name': 'InsurancePolicyProcessing', 'description': 'API to process insurance policy requests', 'createdDate': datetime.datetime(2023, 11, 1, 2, 56, 55, tzinfo=tzlocal()), 'version': '1.0', 'apiKeySource': 'HEADER', 'endpointConfiguration': {'types': ['REGIONAL']}, 'disableExecuteApiEndpoint': False, 'rootResourceId': '0cu1gxefef'}\n"
     ]
    }
   ],
   "source": [
    "response = apigateway.create_rest_api(\n",
    "    name='InsurancePolicyProcessing',\n",
    "    description='API to process insurance policy requests',\n",
    "    version='1.0',\n",
    "    endpointConfiguration={\n",
    "        'types': [\n",
    "            'REGIONAL',\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d816341b-40b5-422c-9af9-c59f735cfff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pqraih5vog\n",
      "0cu1gxefef\n"
     ]
    }
   ],
   "source": [
    "rest_api_id = response['id']\n",
    "print(rest_api_id)\n",
    "\n",
    "# Get the rest api's root id\n",
    "root_resource_id = apigateway.get_resources(\n",
    "    restApiId=rest_api_id\n",
    ")['items'][0]['id']\n",
    "\n",
    "print(root_resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c05629c-a252-4294-bcc2-21bbb2cafb47",
   "metadata": {},
   "source": [
    "Next, create the resources and methods associated with the previously created REST API.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca3a7189-cdc6-4443-b7f8-bb3b62b234f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'db2d4fd8-2189-4193-a51b-bb37711b7ced', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 02:56:57 GMT', 'content-type': 'application/json', 'content-length': '77', 'connection': 'keep-alive', 'x-amzn-requestid': 'db2d4fd8-2189-4193-a51b-bb37711b7ced', 'x-amz-apigw-id': 'NsqzAJVPvHcEd5A='}, 'RetryAttempts': 0}, 'id': 'dyx1gi', 'parentId': '0cu1gxefef', 'pathPart': 'policy', 'path': '/policy'}\n"
     ]
    }
   ],
   "source": [
    "response = apigateway.create_resource(\n",
    "    restApiId=rest_api_id,\n",
    "    parentId=root_resource_id,\n",
    "    pathPart='policy'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dc69f72-a6cf-4141-9b93-6de344db7b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dyx1gi\n"
     ]
    }
   ],
   "source": [
    "api_resource_id = response['id']\n",
    "print(api_resource_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56aead79-c303-4da5-9fa7-bd979d609327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '6fba9501-84a6-43a9-8b5b-ed806537cdff', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 02:56:59 GMT', 'content-type': 'application/json', 'content-length': '135', 'connection': 'keep-alive', 'x-amzn-requestid': '6fba9501-84a6-43a9-8b5b-ed806537cdff', 'x-amz-apigw-id': 'NsqzVL6SvHcEcgg='}, 'RetryAttempts': 0}, 'httpMethod': 'PUT', 'authorizationType': 'NONE', 'apiKeyRequired': False, 'requestParameters': {'method.request.querystring.policy': False}}\n",
      "{'ResponseMetadata': {'RequestId': '073b451f-5683-41db-86dd-66dedf9269c8', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 02:56:59 GMT', 'content-type': 'application/json', 'content-length': '67', 'connection': 'keep-alive', 'x-amzn-requestid': '073b451f-5683-41db-86dd-66dedf9269c8', 'x-amz-apigw-id': 'NsqzWIl7vHcEdnQ='}, 'RetryAttempts': 0}, 'statusCode': '200', 'responseModels': {'application/json': 'Empty'}}\n"
     ]
    }
   ],
   "source": [
    "# Add a put method to the rest api resource\n",
    "api_put_method = apigateway.put_method(\n",
    "  restApiId=rest_api_id,\n",
    "  resourceId=api_resource_id,\n",
    "  httpMethod='PUT',\n",
    "  authorizationType='NONE',\n",
    "  requestParameters={\n",
    "      'method.request.querystring.policy': False\n",
    "  }\n",
    ")\n",
    "\n",
    "api_put_response = apigateway.put_method_response(\n",
    "    restApiId=rest_api_id,\n",
    "    resourceId=api_resource_id,\n",
    "    httpMethod='PUT',\n",
    "    statusCode='200',\n",
    "    responseModels={\n",
    "        'application/json': 'Empty'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(api_put_method)\n",
    "print(api_put_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a137533-611a-4624-8143-41ef7ae3e39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'a01a7879-4c77-42ed-9b9b-67c26de10ed7', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 02:57:00 GMT', 'content-type': 'application/json', 'content-length': '193', 'connection': 'keep-alive', 'x-amzn-requestid': 'a01a7879-4c77-42ed-9b9b-67c26de10ed7', 'x-amz-apigw-id': 'NsqzgKn7vHcEdkg='}, 'RetryAttempts': 0}, 'type': 'MOCK', 'requestTemplates': {'application/json': '{\"statusCode\": 200 }'}, 'passthroughBehavior': 'WHEN_NO_MATCH', 'timeoutInMillis': 29000, 'cacheNamespace': 'dyx1gi', 'cacheKeyParameters': []}\n",
      "{'ResponseMetadata': {'RequestId': '88b57636-5c6c-463a-8dc9-57263b7e0f2b', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 02:57:00 GMT', 'content-type': 'application/json', 'content-length': '87', 'connection': 'keep-alive', 'x-amzn-requestid': '88b57636-5c6c-463a-8dc9-57263b7e0f2b', 'x-amz-apigw-id': 'NsqzgJFyPHcEcOg='}, 'RetryAttempts': 0}, 'statusCode': '200', 'responseTemplates': {'application/json': '{\"statusCode\": 200 }'}}\n"
     ]
    }
   ],
   "source": [
    "put_integration = apigateway.put_integration(\n",
    "    restApiId=rest_api_id,\n",
    "    resourceId=api_resource_id,\n",
    "    httpMethod='PUT',\n",
    "    type='MOCK',\n",
    "    integrationHttpMethod='PUT',\n",
    "    requestTemplates={\n",
    "      \"application/json\": \"{\\\"statusCode\\\": 200 }\"\n",
    "    }\n",
    ")\n",
    "\n",
    "put_integration_response = apigateway.put_integration_response(\n",
    "    restApiId=rest_api_id,\n",
    "    resourceId=api_resource_id,\n",
    "    httpMethod='PUT',\n",
    "    statusCode='200',\n",
    "    responseTemplates={\n",
    "        \"application/json\": \"{\\\"statusCode\\\": 200 }\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(put_integration)\n",
    "print(put_integration_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d83700f3-816b-471f-8835-9e6a1aa61dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'bcdbd167-ccde-44b7-8155-f962acb88c81', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 02:57:03 GMT', 'content-type': 'application/json', 'content-length': '138', 'connection': 'keep-alive', 'x-amzn-requestid': 'bcdbd167-ccde-44b7-8155-f962acb88c81', 'x-amz-apigw-id': 'Nsqz5KTWPHcEddA='}, 'RetryAttempts': 0}, 'httpMethod': 'DELETE', 'authorizationType': 'NONE', 'apiKeyRequired': False, 'requestParameters': {'method.request.querystring.policy': False}}\n",
      "{'ResponseMetadata': {'RequestId': '85ab69c2-ea2d-4ba4-805f-bf8be27126a1', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 02:57:03 GMT', 'content-type': 'application/json', 'content-length': '67', 'connection': 'keep-alive', 'x-amzn-requestid': '85ab69c2-ea2d-4ba4-805f-bf8be27126a1', 'x-amz-apigw-id': 'Nsqz6KiWPHcEb6w='}, 'RetryAttempts': 0}, 'statusCode': '200', 'responseModels': {'application/json': 'Empty'}}\n"
     ]
    }
   ],
   "source": [
    "# Add a delete method to the rest api resource\n",
    "api_delete_method = apigateway.put_method(\n",
    "  restApiId=rest_api_id,\n",
    "  resourceId=api_resource_id,\n",
    "  httpMethod='DELETE',\n",
    "  authorizationType='NONE',\n",
    "  requestParameters={\n",
    "      'method.request.querystring.policy': False\n",
    "  }\n",
    ")\n",
    "\n",
    "api_delete_response = apigateway.put_method_response(\n",
    "    restApiId=rest_api_id,\n",
    "    resourceId=api_resource_id,\n",
    "    httpMethod='DELETE',\n",
    "    statusCode='200',\n",
    "    #responseParameters={\n",
    "    #    'string': True|False\n",
    "    #},\n",
    "    responseModels={\n",
    "        'application/json': 'Empty'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(api_delete_method)\n",
    "print(api_delete_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4eb7af9-a627-4647-866d-2fdb1b5a9e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '1ba42a8d-ddc3-4b1f-949c-e7ddedea620a', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 02:57:04 GMT', 'content-type': 'application/json', 'content-length': '193', 'connection': 'keep-alive', 'x-amzn-requestid': '1ba42a8d-ddc3-4b1f-949c-e7ddedea620a', 'x-amz-apigw-id': 'Nsq0FJ2IvHcEdYQ='}, 'RetryAttempts': 0}, 'type': 'MOCK', 'requestTemplates': {'application/json': '{\"statusCode\": 200 }'}, 'passthroughBehavior': 'WHEN_NO_MATCH', 'timeoutInMillis': 29000, 'cacheNamespace': 'dyx1gi', 'cacheKeyParameters': []}\n",
      "{'ResponseMetadata': {'RequestId': 'f92bae72-2104-414c-861c-88a2a6af7d29', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 02:57:04 GMT', 'content-type': 'application/json', 'content-length': '87', 'connection': 'keep-alive', 'x-amzn-requestid': 'f92bae72-2104-414c-861c-88a2a6af7d29', 'x-amz-apigw-id': 'Nsq0GJqAPHcEcWg='}, 'RetryAttempts': 0}, 'statusCode': '200', 'responseTemplates': {'application/json': '{\"statusCode\": 200 }'}}\n"
     ]
    }
   ],
   "source": [
    "delete_integration = apigateway.put_integration(\n",
    "    restApiId=rest_api_id,\n",
    "    resourceId=api_resource_id,\n",
    "    httpMethod='DELETE',\n",
    "    type='MOCK',\n",
    "    integrationHttpMethod='DELETE',\n",
    "    requestTemplates={\n",
    "      \"application/json\": \"{\\\"statusCode\\\": 200 }\"      \n",
    "    },\n",
    "  )\n",
    "\n",
    "delete_integration_response = apigateway.put_integration_response(\n",
    "    restApiId=rest_api_id,\n",
    "    resourceId=api_resource_id,\n",
    "    httpMethod='DELETE',\n",
    "    statusCode='200',\n",
    "    responseTemplates={\n",
    "        \"application/json\": \"{\\\"statusCode\\\": 200 }\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(delete_integration)\n",
    "print(delete_integration_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60213e4-3811-468a-b6ea-a76c78a7ede3",
   "metadata": {},
   "source": [
    "Finally, deploy the API to create an endpoint.  This endpoint will be used later in the notebook when we configure the tools that will be made available to our LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "372ad38a-0213-4f48-8c65-c8ce3760b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy API\n",
    "\n",
    "deploy_api = apigateway.create_deployment(\n",
    "    restApiId=rest_api_id,\n",
    "    stageName='Mock-Test',\n",
    "    stageDescription='Mock Testing for Insurance API',\n",
    "    description='Mock Testing API',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46598fd1-d81f-4210-9d7d-784064dff5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'ab72a56f-8fcc-43db-9773-fa9e42bcfd77', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Wed, 01 Nov 2023 02:57:05 GMT', 'content-type': 'application/json', 'content-length': '74', 'connection': 'keep-alive', 'x-amzn-requestid': 'ab72a56f-8fcc-43db-9773-fa9e42bcfd77', 'x-amz-apigw-id': 'Nsq0RKTjPHcEdgQ='}, 'RetryAttempts': 0}, 'id': 'z9sj10', 'description': 'Mock Testing API', 'createdDate': datetime.datetime(2023, 11, 1, 2, 57, 5, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "print(deploy_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaf211eb-6af3-4cdb-a963-ca2fa885912f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z9sj10\n"
     ]
    }
   ],
   "source": [
    "deployment_id = deploy_api['id']\n",
    "print(deployment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7ee449f-1b00-43b0-9a37-3abc5d40b195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pqraih5vog.execute-api.us-west-2.amazonaws.com/Mock-Test/policy\n"
     ]
    }
   ],
   "source": [
    "# Get URLs\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "request_url = f\"https://{rest_api_id}.execute-api.{region}.amazonaws.com/Mock-Test/policy\"\n",
    "print(request_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d568a15a-6a98-4c8f-87d4-7c25e1e0cbc3",
   "metadata": {},
   "source": [
    "# Prepare the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7116c7e-8052-4507-a8c1-f77763264485",
   "metadata": {},
   "source": [
    "## LLaMa-2-13B-Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3425bc-4444-4a90-8985-30a76ccaad71",
   "metadata": {},
   "source": [
    "To show diversity in approaches, you will use a local LLaMa-2-13B-Chat model to generate SQL to query the database you just made. This will be a 5-bit quantized version of the model, running on your notebook CPU.\n",
    "\n",
    "This GGUF version of the model can be found at [TheBloke/Llama-2-13B-chat-GGUF](https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF) in the HuggingFace Model Repo.\n",
    "\n",
    "This model is a quantized version of [Meta's LLaMa-2-13B-Chat](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbd6f9e3-5084-476b-a268-cd9250f0f178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/llama-2-13b-chat.Q5_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_model_dir = \"models\"\n",
    "model_repo = \"TheBloke/Llama-2-13b-Chat-GGUF\"\n",
    "model_filename = \"llama-2-13b-chat.Q5_K_M.gguf\"\n",
    "\n",
    "model_filepath = Path(local_model_dir + \"/\" + model_filename)\n",
    "\n",
    "hf_hub_download(repo_id=model_repo, filename=model_filename, local_dir=local_model_dir)\n",
    "\n",
    "print(model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a89458c-660d-4359-aecf-3da4b8a90321",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from models/llama-2-13b-chat.Q5_K_M.gguf (version GGUF V2 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q5_K     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:             blk.15.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:             blk.15.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.2.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:            blk.2.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.2.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.2.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.2.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:              blk.2.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:         blk.2.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.2.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.2.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.3.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:            blk.3.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.3.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.3.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.3.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:              blk.3.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:         blk.3.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.3.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.3.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.4.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:            blk.4.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.4.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.4.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.4.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:              blk.4.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:         blk.4.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:              blk.4.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:              blk.4.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.5.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:            blk.5.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:            blk.5.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:              blk.5.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:            blk.5.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:              blk.5.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:         blk.5.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:              blk.5.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:              blk.5.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.6.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:            blk.6.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:            blk.6.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:              blk.6.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:            blk.6.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:              blk.6.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:         blk.6.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:              blk.6.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:              blk.6.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:           blk.7.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:            blk.7.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.7.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.7.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:            blk.7.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.7.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:         blk.7.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:              blk.7.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:              blk.7.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.8.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:            blk.8.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:            blk.8.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:              blk.8.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:            blk.8.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:              blk.8.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:         blk.8.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:              blk.8.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:              blk.8.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.9.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:            blk.9.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:            blk.9.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:              blk.9.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:            blk.9.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:              blk.9.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:         blk.9.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:              blk.9.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:              blk.9.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:          blk.15.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:           blk.15.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:        blk.15.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.15.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.16.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.16.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.16.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.16.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:          blk.17.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:           blk.17.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:           blk.17.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:        blk.17.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:             blk.17.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:             blk.17.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.18.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:        blk.18.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:             blk.18.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:             blk.18.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.19.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:        blk.19.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:             blk.19.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:             blk.19.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.20.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:        blk.20.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:             blk.20.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.20.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:          blk.21.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:           blk.21.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:           blk.21.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:             blk.21.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:        blk.21.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:             blk.21.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:             blk.21.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.22.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:        blk.22.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:             blk.22.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.23.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:        blk.23.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:             blk.23.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.24.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:        blk.24.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:             blk.24.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.25.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:        blk.25.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:             blk.25.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:          blk.26.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:           blk.26.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:             blk.26.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:        blk.26.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:             blk.26.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:           blk.27.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:             blk.27.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:        blk.27.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:             blk.27.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.28.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:             blk.28.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:        blk.28.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:             blk.28.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:           blk.29.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:             blk.29.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:        blk.29.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:             blk.29.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:                    output.weight q6_K     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:          blk.32.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  291:           blk.32.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  292:           blk.32.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  293:             blk.32.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  294:           blk.32.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  295:             blk.32.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  296:        blk.32.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  297:             blk.32.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  298:             blk.32.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  299:          blk.33.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  300:           blk.33.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  301:           blk.33.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  302:             blk.33.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  303:           blk.33.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  304:             blk.33.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  305:        blk.33.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  306:             blk.33.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  307:             blk.33.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  308:          blk.34.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  309:           blk.34.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  310:           blk.34.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  311:             blk.34.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  312:           blk.34.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  313:             blk.34.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  314:        blk.34.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  315:             blk.34.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  316:             blk.34.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  317:          blk.35.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  318:           blk.35.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  319:           blk.35.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  320:             blk.35.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  321:           blk.35.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  322:             blk.35.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  323:        blk.35.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  324:             blk.35.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  325:             blk.35.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  326:          blk.36.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  327:           blk.36.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  328:           blk.36.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  329:             blk.36.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  330:           blk.36.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  331:             blk.36.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  332:        blk.36.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  333:             blk.36.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  334:             blk.36.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  335:          blk.37.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  336:           blk.37.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  337:           blk.37.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  338:             blk.37.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  339:           blk.37.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  340:             blk.37.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  341:        blk.37.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  342:             blk.37.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  343:             blk.37.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  344:          blk.38.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  345:           blk.38.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  346:           blk.38.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  347:             blk.38.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  348:           blk.38.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  349:             blk.38.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  350:        blk.38.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  351:             blk.38.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  352:             blk.38.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  353:          blk.39.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  354:           blk.39.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  355:           blk.39.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  356:             blk.39.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  357:           blk.39.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  358:             blk.39.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  359:        blk.39.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  360:             blk.39.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  361:             blk.39.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  362:               output_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                          general.file_type u32     \n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  18:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  241 tensors\n",
      "llama_model_loader: - type q6_K:   41 tensors\n",
      "llm_load_print_meta: format           = GGUF V2 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = mostly Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.60 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name   = LLaMA v2\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.12 MB\n",
      "llm_load_tensors: mem required  = 8801.75 MB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  = 3200.00 MB\n",
      "llama_new_context_with_model: compute buffer total size = 11.47 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "# Callbacks support token-wise streaming if desired\n",
    "callback_manager = CallbackManager([])\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "llama_llm = LlamaCpp(\n",
    "    model_path=str(model_filepath),\n",
    "    temperature=0.001,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    callback_manager=callback_manager, \n",
    "    verbose=True, # Verbose is required to pass to the callback manager\n",
    "    n_ctx=4096,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dfe95c-b601-4415-8361-7e855d8e4985",
   "metadata": {},
   "source": [
    "## Anthropic's Claude V2 via Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4400d0-840b-4fd4-a7fe-cace4d33c2ab",
   "metadata": {},
   "source": [
    "In this example you will use Anthropic's Claude V2 as the LLM for the reasoning part of the ReAct approach in the form of a [Langchain Agent](https://python.langchain.com/docs/modules/agents/). This model will be responsible for accepting the request, breaking down the chain of thought reasoning, selecting tools, and formulate a final response.\n",
    "\n",
    "[Amazon Bedrock](https://aws.amazon.com/bedrock/) will provide the interface for Claude in this example, showing how you can leverage this model (and others) though an API instead of hosting your own endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e47ea28-ff62-430a-829a-01ed4feaf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Bedrock\n",
    "\n",
    "llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2\", \n",
    "    model_kwargs={'max_tokens_to_sample':10000}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2c54e-946f-484c-9f7a-2a9b72cc072b",
   "metadata": {},
   "source": [
    "## Interfacing with a database via Langchain SQLDatabaseChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d54f4-bd4f-45d9-a5aa-6c85314ebc78",
   "metadata": {},
   "source": [
    "In this section you will build the foudational element for a tool you will create later, which will take a natural language query and return a response from the in-memory SQLite database.\n",
    "\n",
    "You'll accomplish this by creating a Langchain SQLDatabase chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60f00101-10b9-4f01-aae2-f7d05210552c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fb6e2-5aa8-46bd-af5a-4e45fb50780e",
   "metadata": {},
   "source": [
    "Below you can see an example prompt for your SQLDatabaseChain.\n",
    "\n",
    "It accepts:\n",
    "- `dialect`: parameter for the dialect of the target database\n",
    "- `table_info`: parameter that will autogenerate a sample of the schemas and first few rows of data from the tables\n",
    "- `input`: parameter for the input NLP query to generate SQL from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e86ea3cc-2386-4723-96ca-96a49312162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "_DEFAULT_TEMPLATE = \"\"\"\n",
    "You are a {dialect} expert. Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per {dialect}. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\\\") to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use date('now') function to get the current date, if the question involves \\\"today\\\".\n",
    "\n",
    "Once you have a SQLResult, use it to formulate a natural language answer. Example: The policy id is 12345.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: SQL Query to run\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "Only use the following tables:\n",
    "{table_info}\n",
    "\n",
    "Question: {input}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"input\", \"table_info\", \"dialect\"], template=_DEFAULT_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4961fd-6d9d-4d73-a624-e55300b4cc7e",
   "metadata": {},
   "source": [
    "Create a SQLDatabase object from the DB engine created earlier for the SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78da1902-468d-46db-8612-07a1ddf8cfa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = SQLDatabase(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201ea63-c676-4627-a556-aae8cee0ec13",
   "metadata": {},
   "source": [
    "You can test your SQLDatabaseChain with a sample NLP query that will be the foundation of a later example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a26699b3-7464-4db8-bc64-343b7914eccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_chain = SQLDatabaseChain.from_llm(llm=llama_llm, db=db, verbose=True, prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b93cf-59f1-4fb0-8606-26d0ce5ebeff",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can test your SQLDatabaseChain with a sample NLP query that will be the foundation of a later example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2bb5911-51be-4e1e-88f2-97faee7df2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:SQLDatabaseChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is Charles Wise's policy id?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:SQLDatabaseChain > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Charles Wise's policy id?\\nSQLQuery:\",\n",
      "  \"top_k\": \"5\",\n",
      "  \"dialect\": \"sqlite\",\n",
      "  \"table_info\": \"\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\",\n",
      "  \"stop\": [\n",
      "    \"\\nSQLResult:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:SQLDatabaseChain > 2:chain:LLMChain > 3:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"You are a sqlite expert. Given an input question, first create a syntactically correct sqlite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per sqlite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\\\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date('now') function to get the current date, if the question involves \\\"today\\\".\\n\\nOnce you have a SQLResult, use it to formulate a natural language answer. Example: The policy id is 12345.\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\\n\\nQuestion: What is Charles Wise's policy id?\\nSQLQuery:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   808.58 ms\n",
      "llama_print_timings:      sample time =    17.14 ms /    19 runs   (    0.90 ms per token,  1108.19 tokens per second)\n",
      "llama_print_timings: prompt eval time = 43218.41 ms /   580 tokens (   74.51 ms per token,    13.42 tokens per second)\n",
      "llama_print_timings:        eval time =  2077.20 ms /    18 runs   (  115.40 ms per token,     8.67 tokens per second)\n",
      "llama_print_timings:       total time = 45507.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:SQLDatabaseChain > 2:chain:LLMChain > 3:llm:LlamaCpp] [45.51s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" SELECT policy_id FROM policies WHERE first_name = 'Charles';\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:SQLDatabaseChain > 2:chain:LLMChain] [45.51s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" SELECT policy_id FROM policies WHERE first_name = 'Charles';\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:SQLDatabaseChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Charles Wise's policy id?\\nSQLQuery:SELECT policy_id FROM policies WHERE first_name = 'Charles';\\nSQLResult: [(54621,)]\\nAnswer:\",\n",
      "  \"top_k\": \"5\",\n",
      "  \"dialect\": \"sqlite\",\n",
      "  \"table_info\": \"\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\",\n",
      "  \"stop\": [\n",
      "    \"\\nSQLResult:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:SQLDatabaseChain > 4:chain:LLMChain > 5:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"You are a sqlite expert. Given an input question, first create a syntactically correct sqlite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per sqlite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\\\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date('now') function to get the current date, if the question involves \\\"today\\\".\\n\\nOnce you have a SQLResult, use it to formulate a natural language answer. Example: The policy id is 12345.\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\\n\\nQuestion: What is Charles Wise's policy id?\\nSQLQuery:SELECT policy_id FROM policies WHERE first_name = 'Charles';\\nSQLResult: [(54621,)]\\nAnswer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:SQLDatabaseChain > 4:chain:LLMChain > 5:llm:LlamaCpp] [3.56s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" The policy id is 54621.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:SQLDatabaseChain > 4:chain:LLMChain] [3.57s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" The policy id is 54621.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:SQLDatabaseChain] [49.08s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"The policy id is 54621.\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   808.58 ms\n",
      "llama_print_timings:      sample time =    10.88 ms /    12 runs   (    0.91 ms per token,  1102.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2161.87 ms /    30 tokens (   72.06 ms per token,    13.88 tokens per second)\n",
      "llama_print_timings:        eval time =  1353.57 ms /    11 runs   (  123.05 ms per token,     8.13 tokens per second)\n",
      "llama_print_timings:       total time =  3561.66 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The policy id is 54621.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_chain.run(query=\"What is Charles Wise's policy id?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe082a5-7f0f-48ee-83fa-b98fcfe7af24",
   "metadata": {},
   "source": [
    "After running the chain, you can see that it returns a policy id for the person in question. Sometimes you may see that the resulting query is not specfic enough (maybe only looking at `first_name` instead of both `first_name` and `last_name`), but this can be addressed by refining the prompt.\n",
    "\n",
    "However, it will suffice for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22149c01-6a25-4b18-9af4-2cb7f839e1ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build a Langchain APIChain\n",
    "\n",
    "Similar to the previous example showing the use of the SQLLite database in a chain, we'll show how you can utilize the previously created API tool in the context of a chain as well.  This section is showing an APIChain for demonstration purposes but later you'll see how we can use the API as a defined tool as part of our ReAct workflow.  \n",
    "\n",
    "In this example, we'll read in API documentation using an explicit copy of the API's documentation (explicit_docs.txt).  Alternatively, you could have the LLM read this directly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13cd3193-cead-4f0d-83b4-e1585a9261ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_docs = open('explicit_docs.txt', 'r')\n",
    "info = api_docs.read()\n",
    "explicit_docs=info.replace('\\n', '')\n",
    "api_docs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29201891-081c-4f8b-8d9f-58a307a98062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import APIChain\n",
    "\n",
    "API_chain = APIChain.from_llm_and_api_docs(llm, explicit_docs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25275729-187c-4175-9bea-cb6b831ecdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:APIChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Request policy cancellation for policy id 54621\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:APIChain > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Request policy cancellation for policy id 54621\",\n",
      "  \"api_docs\": \"description: Insurance Policy API to update,cancel policyUpdate Method: PUT Cancel Method: DELETE Get Method: GET Sample Base API Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy? Sample Update Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?PUT/4444/7203421165Sample Delete Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/4444Response Format: The response format for this API is in JSON.Authentication: No authentication is required to use this API.Error Codes: The following response codes may be returned by the API:• 200 OK: Successful request.• 400 Bad Request: Invalid parameters.• 401 Unauthorized: Authentication required.• 403 Forbidden: Access denied.• 404 Not Found: Resource not found.• 500 Internal Server Error: Server error.'\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:APIChain > 2:chain:LLMChain > 3:llm:Bedrock] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"You are given the below API Documentation:\\ndescription: Insurance Policy API to update,cancel policyUpdate Method: PUT Cancel Method: DELETE Get Method: GET Sample Base API Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy? Sample Update Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?PUT/4444/7203421165Sample Delete Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/4444Response Format: The response format for this API is in JSON.Authentication: No authentication is required to use this API.Error Codes: The following response codes may be returned by the API:• 200 OK: Successful request.• 400 Bad Request: Invalid parameters.• 401 Unauthorized: Authentication required.• 403 Forbidden: Access denied.• 404 Not Found: Resource not found.• 500 Internal Server Error: Server error.'\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:Request policy cancellation for policy id 54621\\nAPI url:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:APIChain > 2:chain:LLMChain > 3:llm:Bedrock] [2.97s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/54621\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:APIChain > 2:chain:LLMChain] [2.97s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/54621\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:APIChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"Request policy cancellation for policy id 54621\",\n",
      "  \"api_docs\": \"description: Insurance Policy API to update,cancel policyUpdate Method: PUT Cancel Method: DELETE Get Method: GET Sample Base API Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy? Sample Update Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?PUT/4444/7203421165Sample Delete Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/4444Response Format: The response format for this API is in JSON.Authentication: No authentication is required to use this API.Error Codes: The following response codes may be returned by the API:• 200 OK: Successful request.• 400 Bad Request: Invalid parameters.• 401 Unauthorized: Authentication required.• 403 Forbidden: Access denied.• 404 Not Found: Resource not found.• 500 Internal Server Error: Server error.'\",\n",
      "  \"api_url\": \"https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/54621\",\n",
      "  \"api_response\": \"{\\\"message\\\":null}\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:APIChain > 4:chain:LLMChain > 5:llm:Bedrock] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"You are given the below API Documentation:\\ndescription: Insurance Policy API to update,cancel policyUpdate Method: PUT Cancel Method: DELETE Get Method: GET Sample Base API Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy? Sample Update Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?PUT/4444/7203421165Sample Delete Endpoint: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/4444Response Format: The response format for this API is in JSON.Authentication: No authentication is required to use this API.Error Codes: The following response codes may be returned by the API:• 200 OK: Successful request.• 400 Bad Request: Invalid parameters.• 401 Unauthorized: Authentication required.• 403 Forbidden: Access denied.• 404 Not Found: Resource not found.• 500 Internal Server Error: Server error.'\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:Request policy cancellation for policy id 54621\\nAPI url: https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/54621\\n\\nHere is the response from the API:\\n\\n{\\\"message\\\":null}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:APIChain > 4:chain:LLMChain > 5:llm:Bedrock] [5.77s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" The API call to cancel policy 54621 is:\\n\\nhttps://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/54621\\n\\nThe API response of {\\\"message\\\":null} indicates that the cancellation request for policy id 54621 was successful.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:APIChain > 4:chain:LLMChain] [5.77s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" The API call to cancel policy 54621 is:\\n\\nhttps://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/54621\\n\\nThe API response of {\\\"message\\\":null} indicates that the cancellation request for policy id 54621 was successful.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:APIChain] [8.76s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \" The API call to cancel policy 54621 is:\\n\\nhttps://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/54621\\n\\nThe API response of {\\\"message\\\":null} indicates that the cancellation request for policy id 54621 was successful.\"\n",
      "}\n",
      " The API call to cancel policy 54621 is:\n",
      "\n",
      "https://qglixpuz4c.execute-api.us-west-2.amazonaws.com/Mock-Test/policy?DELETE/54621\n",
      "\n",
      "The API response of {\"message\":null} indicates that the cancellation request for policy id 54621 was successful.\n"
     ]
    }
   ],
   "source": [
    "response = API_chain.run(\"Request policy cancellation for policy id 54621\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1998fa-aeee-40f0-b3b5-ba46a21d3ed1",
   "metadata": {},
   "source": [
    "## Setting up Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec956d-eeaa-4963-8f1e-4dea99eac2cd",
   "metadata": {},
   "source": [
    "With the foundational components now in place, you will begin setting up the concept of tools. Tools are purpose built components to satisfy a particular need. They can look up data, run API commands, or even go perform searches on the internet to satisfy the needs of the reasoning chain of thought.\n",
    "\n",
    "As you proceed you'll see how to built an extensible toolbox that will attempt to automatically select the right tools based on the input query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda280d-008f-445d-a2bb-580701515c3b",
   "metadata": {},
   "source": [
    "### Create API Tool\n",
    "\n",
    "First, we'll define the API Tool that will be made available to our ReAct workflow.   This API tool will utilize the previously created insurance policy API.  \n",
    "\n",
    "For this, we are using LangChain's [StructuredTool](https://blog.langchain.dev/structured-tools/) which allows us to represent a function as a tool that an agent can easily interface with to perform actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a325208a-c993-40cb-8c09-90664c246e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://pqraih5vog.execute-api.us-west-2.amazonaws.com/Mock-Test/policy'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83f16fa0-1284-4d6c-966a-0d6a6d2c7c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "# A structured tool represents an action an agent can take. It wraps any function you provide to let an agent easily interface with it.\n",
    "    \n",
    "def cancel_policy_request(request: str): \n",
    "    \"\"\"Sends a DELETE request to the policy API with the provided policy id\"\"\"\n",
    "    url = request_url\n",
    "    policy_id = request.rsplit(None, 1)[-1]\n",
    "    result = requests.delete(url+\"?DELETE/\"+policy_id)\n",
    "    return f\"Successfully submitted policy cancellation for: {policy_id}, Status: {result.status_code} - {result.text}\"\n",
    "\n",
    "def update_policy_request(request: str):\n",
    "    \"\"\"Sends a PUT request to the policy API with the provided policy id and data to update\"\"\"\n",
    "    url = request_url\n",
    "    policy_id = request[request.find(\"policy\")+len(\"policy\"):].split()[0]\n",
    "    update_field = request[request.find(\"update the\")+len(\"update the\"):].split()[0]\n",
    "    update_data = request.rsplit(None, 1)[-1]\n",
    "    result = requests.put(url+\"?PUT/\"+policy_id, update_field+\"/\"+update_data)\n",
    "    return f\"Successfully submitted update for: {policy_id}, Update for: {update_field}, {update_data}, Status: {result.status_code} - {result.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1f69aef-4c27-46fd-8029-1d6b804c0eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_policy_request = StructuredTool.from_function(update_policy_request)\n",
    "cancel_policy_request = StructuredTool.from_function(cancel_policy_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d009d62-1f9c-4e4e-ac4a-6014c7271aff",
   "metadata": {},
   "source": [
    "Test the newly created tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "575cf842-d513-4abb-9f7e-d26e31b6fbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:tool:cancel_policy_request] Entering Tool run with input:\n",
      "\u001b[0m\"the policy id is 54621\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:tool:cancel_policy_request] [113ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Successfully submitted policy cancellation for: 54621, Status: 200 - {\"statusCode\": 200 }\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Successfully submitted policy cancellation for: 54621, Status: 200 - {\"statusCode\": 200 }'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancel_policy_request.run('the policy id is 54621')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef1760c7-0787-4f61-af09-dddbf6da41ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:tool:update_policy_request] Entering Tool run with input:\n",
      "\u001b[0m\"Submit a request to update the phone number in policy 54621 to 333-321-5622\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:tool:update_policy_request] [21ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Successfully submitted update for: 54621, Update for: phone, 333-321-5622, Status: 200 - {\"statusCode\": 200 }\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Successfully submitted update for: 54621, Update for: phone, 333-321-5622, Status: 200 - {\"statusCode\": 200 }'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_policy_request.run('Submit a request to update the phone number in policy 54621 to 333-321-5622')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c4fae-853d-4c9b-a9fb-75e5cc69c3d4",
   "metadata": {},
   "source": [
    "Let's now take all of the tools that we've created and add them all to the list of tools that will be made available to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c31fc62d-4ba0-4dc0-9d06-f7b1d236bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import load_tools\n",
    "from langchain.tools import Tool\n",
    "\n",
    "llm_math = LLMMathChain.from_llm(llm, verbose=True)\n",
    "\n",
    "ALL_TOOLS = [\n",
    "        Tool(\n",
    "            name=\"calculator\",\n",
    "            func=llm_math.run,\n",
    "            description=\"Useful when you need to perform mathematical operations.\"\n",
    "        ),    \n",
    "        Tool(\n",
    "            name=\"insurance_policy_lookup\",\n",
    "            func=sql_chain.run,\n",
    "            description=\"Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"cancel_policy_request\",\n",
    "            func=cancel_policy_request.run,\n",
    "            description=\"Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"update_policy_request\",\n",
    "            func=update_policy_request.run,\n",
    "            description=\"Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\"\n",
    "        ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38bfe5-7313-4a4a-9d6d-104c8bb63284",
   "metadata": {},
   "source": [
    "## Dynamic Tool Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac8478-3d00-46d2-a377-cf11e7f23e41",
   "metadata": {},
   "source": [
    "An [embedding model](https://huggingface.co/blog/getting-started-with-embeddings) takes a text string and converts it into a numerical vector representation, which will allow you to store it in a vector database and query it based on semantic similarity.\n",
    "\n",
    "Here, you will host a local [MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) embedding model, which will generate a set of embeddings to help semantically search for the right tools in the example.\n",
    "\n",
    "**Note: Ignore any \"Error displaying widget: model not found\" errors you may see here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abde9a56-ac00-4c51-b24d-0a0611ea90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e314c-e06f-4be2-a5ce-0981825e7e75",
   "metadata": {},
   "source": [
    "The vector store method of tool selection in this example uses [Meta's Facebook AI Similarity Search (FAISS)](https://github.com/facebookresearch/faiss) as a vector database. There are many other options available as well.\n",
    "\n",
    "First you will create a set of documents (one for each tool), that you will vectorize and use to determine best match for tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b97abf3-519e-42d2-98f6-91f9639e0c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Useful when you need to perform mathematical operations.', metadata={'index': 0}),\n",
       " Document(page_content=\"Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\", metadata={'index': 1}),\n",
       " Document(page_content=\"Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\", metadata={'index': 2}),\n",
       " Document(page_content=\"Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\", metadata={'index': 3})]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=t.description, metadata={\"index\": i})\n",
    "    for i, t in enumerate(ALL_TOOLS)\n",
    "]\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b0676-71a0-4f46-829c-104e629614c9",
   "metadata": {},
   "source": [
    "FAISS provides a `from_documents` method for automatically generating embeddings and storing them in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5a4a233-3daf-4c03-ae6d-65e361b20efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a119c3-ce84-4f85-ae38-484175465b5a",
   "metadata": {},
   "source": [
    "In this section you will define the `get_tools` method, which will embed the input query and find relevant documents that are semantically close. This will allow you to take large lists of tools and scope them down to the most relevant ones.\n",
    "\n",
    "You'll use this method to demonstrate tool scoping below and it will also be used in supplying a list of tools to your agent later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68be0fb1-3815-40d1-90b0-3766c4fa813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "\n",
    "def get_tools(query):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    return [ALL_TOOLS[d.metadata[\"index\"]] for d in docs]\n",
    "\n",
    "def print_tools(tools_arr):\n",
    "    for tool in tools_arr:\n",
    "        print(f'{tool}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0a5ba-1650-4de6-8859-42358ceb16c6",
   "metadata": {},
   "source": [
    "Let's see if we can find the right tool for a given input..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d3b3a3-c83b-4293-a3a3-58841dcb04fc",
   "metadata": {},
   "source": [
    "Here you get a list of tools for a mathematical input query. Notice that the `calculator` tool is listed first as its description most closely matches the request. \n",
    "\n",
    "You can also control how many results to return by modifying the `get_relevant_documents` request inside of `get_tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2750fc1-05f1-443f-8b7c-ca18d52a08b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='insurance_policy_lookup' description=\"Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\" func=<bound method Chain.run of SQLDatabaseChain(verbose=True, llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['dialect', 'input', 'table_info'], template='\\nYou are a {dialect} expert. Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per {dialect}. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date(\\'now\\') function to get the current date, if the question involves \"today\".\\n\\nOnce you have a SQLResult, use it to formulate a natural language answer. Example: The policy id is 12345.\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n{table_info}\\n\\nQuestion: {input}'), llm=LlamaCpp(callbacks=<langchain.callbacks.manager.CallbackManager object at 0x7fc5eda0b9a0>, client=<llama_cpp.llama.Llama object at 0x7fc5eda0b7c0>, model_path='models/llama-2-13b-chat.Q5_K_M.gguf', n_ctx=4096, temperature=0.001, top_p=1.0)), database=<langchain.utilities.sql_database.SQLDatabase object at 0x7fc252ff54e0>)>\n",
      "\n",
      "\n",
      "name='update_policy_request' description=\"Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\" func=<bound method BaseTool.run of StructuredTool(name='update_policy_request', description='update_policy_request(request: str) - Sends a PUT request to the policy API with the provided policy id and data to update', args_schema=<class 'pydantic.v1.main.update_policy_requestSchemaSchema'>, func=<function update_policy_request at 0x7fc252fc3910>)>\n",
      "\n",
      "\n",
      "name='cancel_policy_request' description=\"Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\" func=<bound method BaseTool.run of StructuredTool(name='cancel_policy_request', description='cancel_policy_request(request: str) - Sends a DELETE request to the policy API with the provided policy id', args_schema=<class 'pydantic.v1.main.cancel_policy_requestSchemaSchema'>, func=<function cancel_policy_request at 0x7fc252fc39a0>)>\n",
      "\n",
      "\n",
      "name='calculator' description='Useful when you need to perform mathematical operations.' func=<bound method Chain.run of LLMMathChain(verbose=True, llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=Bedrock(client=<botocore.client.BedrockRuntime object at 0x7fc253db7fa0>, model_id='anthropic.claude-v2', model_kwargs={'max_tokens_to_sample': 10000})))>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tools(get_tools(\"What is the policy id for Bob Jones?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdef5887-2059-4c23-912c-7556b9836cfe",
   "metadata": {},
   "source": [
    "Alternatively, the `insurance_policy_lookup` tool is a better match for a policy related inquiry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed3b9999-0f8f-4cb3-88d6-f21dca18835c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='cancel_policy_request' description=\"Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\" func=<bound method BaseTool.run of StructuredTool(name='cancel_policy_request', description='cancel_policy_request(request: str) - Sends a DELETE request to the policy API with the provided policy id', args_schema=<class 'pydantic.v1.main.cancel_policy_requestSchemaSchema'>, func=<function cancel_policy_request at 0x7fc252fc39a0>)>\n",
      "\n",
      "\n",
      "name='update_policy_request' description=\"Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\" func=<bound method BaseTool.run of StructuredTool(name='update_policy_request', description='update_policy_request(request: str) - Sends a PUT request to the policy API with the provided policy id and data to update', args_schema=<class 'pydantic.v1.main.update_policy_requestSchemaSchema'>, func=<function update_policy_request at 0x7fc252fc3910>)>\n",
      "\n",
      "\n",
      "name='insurance_policy_lookup' description=\"Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\" func=<bound method Chain.run of SQLDatabaseChain(verbose=True, llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['dialect', 'input', 'table_info'], template='\\nYou are a {dialect} expert. Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per {dialect}. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date(\\'now\\') function to get the current date, if the question involves \"today\".\\n\\nOnce you have a SQLResult, use it to formulate a natural language answer. Example: The policy id is 12345.\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n{table_info}\\n\\nQuestion: {input}'), llm=LlamaCpp(callbacks=<langchain.callbacks.manager.CallbackManager object at 0x7fc5eda0b9a0>, client=<llama_cpp.llama.Llama object at 0x7fc5eda0b7c0>, model_path='models/llama-2-13b-chat.Q5_K_M.gguf', n_ctx=4096, temperature=0.001, top_p=1.0)), database=<langchain.utilities.sql_database.SQLDatabase object at 0x7fc252ff54e0>)>\n",
      "\n",
      "\n",
      "name='calculator' description='Useful when you need to perform mathematical operations.' func=<bound method Chain.run of LLMMathChain(verbose=True, llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=Bedrock(client=<botocore.client.BedrockRuntime object at 0x7fc253db7fa0>, model_id='anthropic.claude-v2', model_kwargs={'max_tokens_to_sample': 10000})))>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tools(get_tools(\"Cancel the policy for policy id 4325\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce42cbc-52e4-40f5-b634-5c1bca0502ac",
   "metadata": {},
   "source": [
    "# Agent Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f992b52-3680-43fd-ae1e-e6e87e51a826",
   "metadata": {},
   "source": [
    "With you models ready to go, and your toolbox configured, you're ready to setup your ReAct agent.\n",
    "\n",
    "The agent will take in a ReAct style prompt along with the list of tools to build out the chain of thought reasoning and resulting actions.\n",
    "\n",
    "The Langchain agent initialization takes 3 prompt keyword arguments to customize the agent's prompt:\n",
    "- `prefix`: the beginning of the prompt\n",
    "- \\<list of tools and their descriptions is automatically injected here\\>\n",
    "- `format_instructions`: how to format the intermediary and final responses, this is important in dictating how the chain of thought is created and processed.\n",
    "- `suffix`: The invocation of the agent. This contains the initial input request as well as the conversational chain to determine what the agent has already done and seen.\n",
    "\n",
    "Some template parameters you see below are:\n",
    "- `{tool_names}`: this is a list of the tools that are available to the agent, in name only. This helps direct the agent into what to supply as actions during reasoning. In this case the agent will do this step for you, but in others you may need to extract the names yourself.\n",
    "- `{agent_scratchpad}`: this is important as it documents the activities and obserations that the agent has had throughout its reasoning. Without this, you will normally see the agent endlessly loop.\n",
    "- `{input}`: The input request from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fb70dd6-c557-4079-b643-4221f5882c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\"Human: You are an agent tasked with helping look up and modify insurance claims.\n",
    "\n",
    "Given an input request, take a step-by-step approach to find an insurance policy and modify its status.\n",
    "Only use the tools provided.\n",
    "When you have completed the task, end your chain of thought and provide a final response to the user.\n",
    "\n",
    "You have access to the following tools:\"\"\"\n",
    "\n",
    "format_instructions=\"\"\"\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "\n",
    "To use a tool, please use the following format:\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? Yes\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "```\n",
    "\n",
    "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? No\n",
    "Final Answer: [your response here]\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "suffix=\"\"\"\n",
    "Begin!\n",
    "\n",
    "Previous conversation history:{agent_scratchpad}\n",
    "Original input: {input}\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5abd42ac-7ab1-4450-8ea7-9cb733aa1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d147d016-ec63-4c82-ab04-4386fcc86b11",
   "metadata": {},
   "source": [
    "This is the user request that the agent will process using the provided tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dfb3152d-392d-4c44-9588-1d78c2858b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Cancel Charles Wise's insurance policy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf4fd87-f421-46a7-8174-3f6357c3a4c4",
   "metadata": {},
   "source": [
    "Here you will set up your agent.\n",
    "\n",
    "initialize_agent has the following configuration:\n",
    "- `agent`: using the [ZERO_SHOT_REACT agent](https://python.langchain.com/docs/modules/agents/agent_types/react#using-zeroshotreactagent)\n",
    "- `agent_kwargs`: variable contains the object with all of the customized prompt information.\n",
    "- `tools`: list of tools from the vector store, dynamically generated from the input query\n",
    "- `llm`: the agent LLM (in this case Claude V2 from Amazon Bedrock)\n",
    "- `verbose`: show all the details for learning purposes\n",
    "- `return_intermediate_steps`: important for retaining all of the thoughts/actions/observations in the agent_scratchpad\n",
    "- `max_iterations`: VERY IMPORTANT for ensuring that your agent doesn't endlessly loop and run away. Prevents the agent from hammering on the associated LLM.\n",
    "- `handle_parsing_errors`: used for dealing with issues parsing the output of a given step, not necessary but catches edge cases in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1820b8cd-3b19-4f03-bdf0-55a84749edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = get_tools(query)\n",
    "\n",
    "agent_kwargs = {\n",
    "    'prefix':prefix,\n",
    "    'suffix':suffix,\n",
    "    'format_instructions':format_instructions\n",
    "}\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs = agent_kwargs,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True,\n",
    "    max_iterations=5,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aead9f-8954-4da1-b439-3056af299598",
   "metadata": {},
   "source": [
    "Finally you can invoke your agent with the input query!\n",
    "\n",
    "The output will be verbose, but if you follow through you will see the chain start/end and invoke tools to get the information and take action until it reaches a conclusion or hits the `max_iterations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82205f93-79ec-4bd9-9430-c322d768fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Cancel Charles Wise's insurance policy\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Cancel Charles Wise's insurance policy\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:Bedrock] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent tasked with helping look up and modify insurance claims.\\n\\nGiven an input request, take a step-by-step approach to find an insurance policy and modify its status.\\nOnly use the tools provided.\\nWhen you have completed the task, end your chain of thought and provide a final response to the user.\\n\\nYou have access to the following tools:\\n\\ncancel_policy_request: Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\\nupdate_policy_request: Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\\ninsurance_policy_lookup: Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\\ncalculator: Useful when you need to perform mathematical operations.\\n\\n\\n\\nUse the following format:\\n\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [cancel_policy_request, update_policy_request, insurance_policy_lookup, calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\n\\n\\nBegin!\\n\\nPrevious conversation history:\\nOriginal input: Cancel Charles Wise's insurance policy\\n\\nAssistant:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:Bedrock] [3.50s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [3.50s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup] Entering Tool run with input:\n",
      "\u001b[0m\"What is Charles Wise's policy id?\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is Charles Wise's policy id?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 6:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Charles Wise's policy id?\\nSQLQuery:\",\n",
      "  \"top_k\": \"5\",\n",
      "  \"dialect\": \"sqlite\",\n",
      "  \"table_info\": \"\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\",\n",
      "  \"stop\": [\n",
      "    \"\\nSQLResult:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 6:chain:LLMChain > 7:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"You are a sqlite expert. Given an input question, first create a syntactically correct sqlite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per sqlite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\\\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date('now') function to get the current date, if the question involves \\\"today\\\".\\n\\nOnce you have a SQLResult, use it to formulate a natural language answer. Example: The policy id is 12345.\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\\n\\nQuestion: What is Charles Wise's policy id?\\nSQLQuery:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   808.58 ms\n",
      "llama_print_timings:      sample time =    17.33 ms /    19 runs   (    0.91 ms per token,  1096.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2323.28 ms /    19 runs   (  122.28 ms per token,     8.18 tokens per second)\n",
      "llama_print_timings:       total time =  2387.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 6:chain:LLMChain > 7:llm:LlamaCpp] [2.39s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" SELECT policy_id FROM policies WHERE first_name = 'Charles';\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 6:chain:LLMChain] [2.39s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" SELECT policy_id FROM policies WHERE first_name = 'Charles';\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 8:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Charles Wise's policy id?\\nSQLQuery:SELECT policy_id FROM policies WHERE first_name = 'Charles';\\nSQLResult: [(54621,)]\\nAnswer:\",\n",
      "  \"top_k\": \"5\",\n",
      "  \"dialect\": \"sqlite\",\n",
      "  \"table_info\": \"\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\",\n",
      "  \"stop\": [\n",
      "    \"\\nSQLResult:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 8:chain:LLMChain > 9:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"You are a sqlite expert. Given an input question, first create a syntactically correct sqlite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per sqlite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\\\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date('now') function to get the current date, if the question involves \\\"today\\\".\\n\\nOnce you have a SQLResult, use it to formulate a natural language answer. Example: The policy id is 12345.\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\\n\\nQuestion: What is Charles Wise's policy id?\\nSQLQuery:SELECT policy_id FROM policies WHERE first_name = 'Charles';\\nSQLResult: [(54621,)]\\nAnswer:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   808.58 ms\n",
      "llama_print_timings:      sample time =    10.89 ms /    12 runs   (    0.91 ms per token,  1102.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2169.69 ms /    30 tokens (   72.32 ms per token,    13.83 tokens per second)\n",
      "llama_print_timings:        eval time =  1312.47 ms /    11 runs   (  119.32 ms per token,     8.38 tokens per second)\n",
      "llama_print_timings:       total time =  3530.14 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 8:chain:LLMChain > 9:llm:LlamaCpp] [3.53s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" The policy id is 54621.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 8:chain:LLMChain] [3.53s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" The policy id is 54621.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain] [5.93s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"The policy id is 54621.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup] [5.93s] Exiting Tool run with output:\n",
      "\u001b[0m\"The policy id is 54621.\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Cancel Charles Wise's insurance policy\",\n",
      "  \"agent_scratchpad\": \" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:LLMChain > 11:llm:Bedrock] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent tasked with helping look up and modify insurance claims.\\n\\nGiven an input request, take a step-by-step approach to find an insurance policy and modify its status.\\nOnly use the tools provided.\\nWhen you have completed the task, end your chain of thought and provide a final response to the user.\\n\\nYou have access to the following tools:\\n\\ncancel_policy_request: Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\\nupdate_policy_request: Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\\ninsurance_policy_lookup: Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\\ncalculator: Useful when you need to perform mathematical operations.\\n\\n\\n\\nUse the following format:\\n\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [cancel_policy_request, update_policy_request, insurance_policy_lookup, calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\n\\n\\nBegin!\\n\\nPrevious conversation history: Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought:\\nOriginal input: Cancel Charles Wise's insurance policy\\n\\nAssistant:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:LLMChain > 11:llm:Bedrock] [2.77s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Thought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:LLMChain] [2.77s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" Thought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 12:tool:cancel_policy_request] Entering Tool run with input:\n",
      "\u001b[0m\"Submit a request to cancel policy for policy id of 54621\"\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 12:tool:cancel_policy_request > 13:tool:cancel_policy_request] Entering Tool run with input:\n",
      "\u001b[0m\"Submit a request to cancel policy for policy id of 54621\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 12:tool:cancel_policy_request > 13:tool:cancel_policy_request] [24ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Successfully submitted policy cancellation for: 54621, Status: 200 - {\"statusCode\": 200 }\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 12:tool:cancel_policy_request] [24ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Successfully submitted policy cancellation for: 54621, Status: 200 - {\"statusCode\": 200 }\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Cancel Charles Wise's insurance policy\",\n",
      "  \"agent_scratchpad\": \" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought: Thought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621\\nObservation: Successfully submitted policy cancellation for: 54621, Status: 200 - {\\\"statusCode\\\": 200 }\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain > 15:llm:Bedrock] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent tasked with helping look up and modify insurance claims.\\n\\nGiven an input request, take a step-by-step approach to find an insurance policy and modify its status.\\nOnly use the tools provided.\\nWhen you have completed the task, end your chain of thought and provide a final response to the user.\\n\\nYou have access to the following tools:\\n\\ncancel_policy_request: Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\\nupdate_policy_request: Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\\ninsurance_policy_lookup: Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\\ncalculator: Useful when you need to perform mathematical operations.\\n\\n\\n\\nUse the following format:\\n\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [cancel_policy_request, update_policy_request, insurance_policy_lookup, calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\n\\n\\nBegin!\\n\\nPrevious conversation history: Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought: Thought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621\\nObservation: Successfully submitted policy cancellation for: 54621, Status: 200 - {\\\"statusCode\\\": 200 }\\nThought:\\nOriginal input: Cancel Charles Wise's insurance policy\\n\\nAssistant:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain > 15:llm:Bedrock] [15.27s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Here is my step-by-step thought process to address your request:\\n\\nThought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup  \\nAction Input: What is Charles Wise's policy id?\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain] [15.28s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" Here is my step-by-step thought process to address your request:\\n\\nThought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup  \\nAction Input: What is Charles Wise's policy id?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup] Entering Tool run with input:\n",
      "\u001b[0m\"What is Charles Wise's policy id?\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup > 17:chain:SQLDatabaseChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is Charles Wise's policy id?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup > 17:chain:SQLDatabaseChain > 18:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Charles Wise's policy id?\\nSQLQuery:\",\n",
      "  \"top_k\": \"5\",\n",
      "  \"dialect\": \"sqlite\",\n",
      "  \"table_info\": \"\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\",\n",
      "  \"stop\": [\n",
      "    \"\\nSQLResult:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup > 17:chain:SQLDatabaseChain > 18:chain:LLMChain > 19:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"You are a sqlite expert. Given an input question, first create a syntactically correct sqlite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per sqlite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\\\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date('now') function to get the current date, if the question involves \\\"today\\\".\\n\\nOnce you have a SQLResult, use it to formulate a natural language answer. Example: The policy id is 12345.\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\\n\\nQuestion: What is Charles Wise's policy id?\\nSQLQuery:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   808.58 ms\n",
      "llama_print_timings:      sample time =    17.42 ms /    19 runs   (    0.92 ms per token,  1090.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2193.88 ms /    19 runs   (  115.47 ms per token,     8.66 tokens per second)\n",
      "llama_print_timings:       total time =  2259.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup > 17:chain:SQLDatabaseChain > 18:chain:LLMChain > 19:llm:LlamaCpp] [2.26s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" SELECT policy_id FROM policies WHERE first_name = 'Charles';\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup > 17:chain:SQLDatabaseChain > 18:chain:LLMChain] [2.26s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" SELECT policy_id FROM policies WHERE first_name = 'Charles';\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup > 17:chain:SQLDatabaseChain > 20:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Charles Wise's policy id?\\nSQLQuery:SELECT policy_id FROM policies WHERE first_name = 'Charles';\\nSQLResult: [(54621,)]\\nAnswer:\",\n",
      "  \"top_k\": \"5\",\n",
      "  \"dialect\": \"sqlite\",\n",
      "  \"table_info\": \"\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\",\n",
      "  \"stop\": [\n",
      "    \"\\nSQLResult:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup > 17:chain:SQLDatabaseChain > 20:chain:LLMChain > 21:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"You are a sqlite expert. Given an input question, first create a syntactically correct sqlite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per sqlite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\\\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date('now') function to get the current date, if the question involves \\\"today\\\".\\n\\nOnce you have a SQLResult, use it to formulate a natural language answer. Example: The policy id is 12345.\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\\n\\nQuestion: What is Charles Wise's policy id?\\nSQLQuery:SELECT policy_id FROM policies WHERE first_name = 'Charles';\\nSQLResult: [(54621,)]\\nAnswer:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup > 17:chain:SQLDatabaseChain > 20:chain:LLMChain > 21:llm:LlamaCpp] [3.74s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" The policy id is 54621.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup > 17:chain:SQLDatabaseChain > 20:chain:LLMChain] [3.74s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" The policy id is 54621.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup > 17:chain:SQLDatabaseChain] [6.00s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"The policy id is 54621.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 16:tool:insurance_policy_lookup] [6.00s] Exiting Tool run with output:\n",
      "\u001b[0m\"The policy id is 54621.\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 22:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Cancel Charles Wise's insurance policy\",\n",
      "  \"agent_scratchpad\": \" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought: Thought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621\\nObservation: Successfully submitted policy cancellation for: 54621, Status: 200 - {\\\"statusCode\\\": 200 }\\nThought: Here is my step-by-step thought process to address your request:\\n\\nThought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup  \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 22:chain:LLMChain > 23:llm:Bedrock] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent tasked with helping look up and modify insurance claims.\\n\\nGiven an input request, take a step-by-step approach to find an insurance policy and modify its status.\\nOnly use the tools provided.\\nWhen you have completed the task, end your chain of thought and provide a final response to the user.\\n\\nYou have access to the following tools:\\n\\ncancel_policy_request: Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\\nupdate_policy_request: Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\\ninsurance_policy_lookup: Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\\ncalculator: Useful when you need to perform mathematical operations.\\n\\n\\n\\nUse the following format:\\n\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [cancel_policy_request, update_policy_request, insurance_policy_lookup, calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\n\\n\\nBegin!\\n\\nPrevious conversation history: Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought: Thought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621\\nObservation: Successfully submitted policy cancellation for: 54621, Status: 200 - {\\\"statusCode\\\": 200 }\\nThought: Here is my step-by-step thought process to address your request:\\n\\nThought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup  \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought:\\nOriginal input: Cancel Charles Wise's insurance policy\\n\\nAssistant:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   808.58 ms\n",
      "llama_print_timings:      sample time =    10.71 ms /    12 runs   (    0.89 ms per token,  1120.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2428.50 ms /    30 tokens (   80.95 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:        eval time =  1257.46 ms /    11 runs   (  114.31 ms per token,     8.75 tokens per second)\n",
      "llama_print_timings:       total time =  3732.73 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 22:chain:LLMChain > 23:llm:Bedrock] [4.24s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Here is my continued step-by-step thought process:\\n\\nThought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621  \",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 22:chain:LLMChain] [4.24s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" Here is my continued step-by-step thought process:\\n\\nThought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621  \"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 24:tool:cancel_policy_request] Entering Tool run with input:\n",
      "\u001b[0m\"Submit a request to cancel policy for policy id of 54621\"\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 24:tool:cancel_policy_request > 25:tool:cancel_policy_request] Entering Tool run with input:\n",
      "\u001b[0m\"Submit a request to cancel policy for policy id of 54621\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 24:tool:cancel_policy_request > 25:tool:cancel_policy_request] [21ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Successfully submitted policy cancellation for: 54621, Status: 200 - {\"statusCode\": 200 }\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 24:tool:cancel_policy_request] [21ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Successfully submitted policy cancellation for: 54621, Status: 200 - {\"statusCode\": 200 }\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Cancel Charles Wise's insurance policy\",\n",
      "  \"agent_scratchpad\": \" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought: Thought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621\\nObservation: Successfully submitted policy cancellation for: 54621, Status: 200 - {\\\"statusCode\\\": 200 }\\nThought: Here is my step-by-step thought process to address your request:\\n\\nThought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup  \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought: Here is my continued step-by-step thought process:\\n\\nThought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621  \\nObservation: Successfully submitted policy cancellation for: 54621, Status: 200 - {\\\"statusCode\\\": 200 }\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:LLMChain > 27:llm:Bedrock] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent tasked with helping look up and modify insurance claims.\\n\\nGiven an input request, take a step-by-step approach to find an insurance policy and modify its status.\\nOnly use the tools provided.\\nWhen you have completed the task, end your chain of thought and provide a final response to the user.\\n\\nYou have access to the following tools:\\n\\ncancel_policy_request: Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\\nupdate_policy_request: Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\\ninsurance_policy_lookup: Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\\ncalculator: Useful when you need to perform mathematical operations.\\n\\n\\n\\nUse the following format:\\n\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [cancel_policy_request, update_policy_request, insurance_policy_lookup, calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\n\\n\\nBegin!\\n\\nPrevious conversation history: Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought: Thought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621\\nObservation: Successfully submitted policy cancellation for: 54621, Status: 200 - {\\\"statusCode\\\": 200 }\\nThought: Here is my step-by-step thought process to address your request:\\n\\nThought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup  \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought: Here is my continued step-by-step thought process:\\n\\nThought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621  \\nObservation: Successfully submitted policy cancellation for: 54621, Status: 200 - {\\\"statusCode\\\": 200 }\\nThought:\\nOriginal input: Cancel Charles Wise's insurance policy\\n\\nAssistant:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:LLMChain > 27:llm:Bedrock] [4.20s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Thought: Do I need to use a tool? No\\n\\nFinal Answer: Based on the previous conversation, I looked up Charles Wise's policy id using the insurance_policy_lookup tool, which returned id 54621. I then submitted a request to cancel policy 54621 using the cancel_policy_request tool, which returned a 200 success status. The original request was to cancel Charles Wise's insurance policy, which I have completed by looking up his policy id and submitting a cancellation request for that id.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 26:chain:LLMChain] [4.20s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" Thought: Do I need to use a tool? No\\n\\nFinal Answer: Based on the previous conversation, I looked up Charles Wise's policy id using the insurance_policy_lookup tool, which returned id 54621. I then submitted a request to cancel policy 54621 using the cancel_policy_request tool, which returned a 200 success status. The original request was to cancel Charles Wise's insurance policy, which I have completed by looking up his policy id and submitting a cancellation request for that id.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [41.97s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Cancel Charles Wise's insurance policy\",\n",
       " 'output': \"Based on the previous conversation, I looked up Charles Wise's policy id using the insurance_policy_lookup tool, which returned id 54621. I then submitted a request to cancel policy 54621 using the cancel_policy_request tool, which returned a 200 success status. The original request was to cancel Charles Wise's insurance policy, which I have completed by looking up his policy id and submitting a cancellation request for that id.\",\n",
       " 'intermediate_steps': [(AgentAction(tool='insurance_policy_lookup', tool_input=\"What is Charles Wise's policy id?\", log=\" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\"),\n",
       "   'The policy id is 54621.'),\n",
       "  (AgentAction(tool='cancel_policy_request', tool_input='Submit a request to cancel policy for policy id of 54621', log=' Thought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621'),\n",
       "   'Successfully submitted policy cancellation for: 54621, Status: 200 - {\"statusCode\": 200 }'),\n",
       "  (AgentAction(tool='insurance_policy_lookup', tool_input=\"What is Charles Wise's policy id?\", log=\" Here is my step-by-step thought process to address your request:\\n\\nThought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup  \\nAction Input: What is Charles Wise's policy id?\"),\n",
       "   'The policy id is 54621.'),\n",
       "  (AgentAction(tool='cancel_policy_request', tool_input='Submit a request to cancel policy for policy id of 54621', log=' Here is my continued step-by-step thought process:\\n\\nThought: Do I need to use a tool? Yes\\nAction: cancel_policy_request\\nAction Input: Submit a request to cancel policy for policy id of 54621  '),\n",
       "   'Successfully submitted policy cancellation for: 54621, Status: 200 - {\"statusCode\": 200 }')]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17a517-6686-4b1f-bbc4-2d97d2b89c63",
   "metadata": {},
   "source": [
    "Let's try to process an update for Charles..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d0c2431d-8296-4e34-b511-8b0bf795275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Update the insurance policy for Charles Wise by updating the phone number to 333-321-5622\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7d0fd6a6-9400-4938-b923-9ca3f66e18fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Update the insurance policy for Charles Wise by updating the phone number to 333-321-5622\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Update the insurance policy for Charles Wise by updating the phone number to 333-321-5622\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:Bedrock] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent tasked with helping look up and modify insurance claims.\\n\\nGiven an input request, take a step-by-step approach to find an insurance policy and modify its status.\\nOnly use the tools provided.\\nWhen you have completed the task, end your chain of thought and provide a final response to the user.\\n\\nYou have access to the following tools:\\n\\ncancel_policy_request: Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\\nupdate_policy_request: Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\\ninsurance_policy_lookup: Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\\ncalculator: Useful when you need to perform mathematical operations.\\n\\n\\n\\nUse the following format:\\n\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [cancel_policy_request, update_policy_request, insurance_policy_lookup, calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\n\\n\\nBegin!\\n\\nPrevious conversation history:\\nOriginal input: Update the insurance policy for Charles Wise by updating the phone number to 333-321-5622\\n\\nAssistant:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:Bedrock] [5.82s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [5.82s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup] Entering Tool run with input:\n",
      "\u001b[0m\"What is Charles Wise's policy id?\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is Charles Wise's policy id?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 6:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Charles Wise's policy id?\\nSQLQuery:\",\n",
      "  \"top_k\": \"5\",\n",
      "  \"dialect\": \"sqlite\",\n",
      "  \"table_info\": \"\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\",\n",
      "  \"stop\": [\n",
      "    \"\\nSQLResult:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 6:chain:LLMChain > 7:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"You are a sqlite expert. Given an input question, first create a syntactically correct sqlite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per sqlite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\\\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date('now') function to get the current date, if the question involves \\\"today\\\".\\n\\nOnce you have a SQLResult, use it to formulate a natural language answer. Example: The policy id is 12345.\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\\n\\nQuestion: What is Charles Wise's policy id?\\nSQLQuery:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 6:chain:LLMChain > 7:llm:LlamaCpp] [2.25s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" SELECT policy_id FROM policies WHERE first_name = 'Charles';\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 6:chain:LLMChain] [2.25s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" SELECT policy_id FROM policies WHERE first_name = 'Charles';\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 8:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"What is Charles Wise's policy id?\\nSQLQuery:SELECT policy_id FROM policies WHERE first_name = 'Charles';\\nSQLResult: [(54621,)]\\nAnswer:\",\n",
      "  \"top_k\": \"5\",\n",
      "  \"dialect\": \"sqlite\",\n",
      "  \"table_info\": \"\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\",\n",
      "  \"stop\": [\n",
      "    \"\\nSQLResult:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 8:chain:LLMChain > 9:llm:LlamaCpp] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"You are a sqlite expert. Given an input question, first create a syntactically correct sqlite query to run, then look at the results of the query and return the answer to the input question.\\nUnless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per sqlite. You can order the results to return the most informative data in the database.\\nNever query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\\\") to denote them as delimited identifiers.\\nPay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\nPay attention to use date('now') function to get the current date, if the question involves \\\"today\\\".\\n\\nOnce you have a SQLResult, use it to formulate a natural language answer. Example: The policy id is 12345.\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n\\nCREATE TABLE policies (\\n\\tpolicy_id INTEGER NOT NULL, \\n\\tfirst_name VARCHAR(50) NOT NULL, \\n\\tlast_name VARCHAR(50) NOT NULL, \\n\\tphone VARCHAR(15) NOT NULL, \\n\\tpolicy_type VARCHAR(25) NOT NULL, \\n\\tpolicy_date DATE NOT NULL, \\n\\tpolicy_value INTEGER NOT NULL, \\n\\tPRIMARY KEY (policy_id)\\n)\\n\\n/*\\n3 rows from policies table:\\npolicy_id\\tfirst_name\\tlast_name\\tphone\\tpolicy_type\\tpolicy_date\\tpolicy_value\\n10157\\tJewel\\tIngram\\t598-338-6133\\thome\\t2023-01-06\\t750000\\n17108\\tMargarito\\tRollins\\t348-321-5711\\tauto\\t2023-01-04\\t75000\\n17565\\tCharmaine\\tHopkins\\t206-566-6359\\thome\\t2023-01-02\\t135000\\n*/\\n\\nQuestion: What is Charles Wise's policy id?\\nSQLQuery:SELECT policy_id FROM policies WHERE first_name = 'Charles';\\nSQLResult: [(54621,)]\\nAnswer:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   808.58 ms\n",
      "llama_print_timings:      sample time =    17.07 ms /    19 runs   (    0.90 ms per token,  1113.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  2179.56 ms /    19 runs   (  114.71 ms per token,     8.72 tokens per second)\n",
      "llama_print_timings:       total time =  2244.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 8:chain:LLMChain > 9:llm:LlamaCpp] [3.54s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" The policy id is 54621.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain > 8:chain:LLMChain] [3.54s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" The policy id is 54621.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup > 5:chain:SQLDatabaseChain] [5.79s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"The policy id is 54621.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:insurance_policy_lookup] [5.79s] Exiting Tool run with output:\n",
      "\u001b[0m\"The policy id is 54621.\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Update the insurance policy for Charles Wise by updating the phone number to 333-321-5622\",\n",
      "  \"agent_scratchpad\": \" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:LLMChain > 11:llm:Bedrock] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent tasked with helping look up and modify insurance claims.\\n\\nGiven an input request, take a step-by-step approach to find an insurance policy and modify its status.\\nOnly use the tools provided.\\nWhen you have completed the task, end your chain of thought and provide a final response to the user.\\n\\nYou have access to the following tools:\\n\\ncancel_policy_request: Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\\nupdate_policy_request: Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\\ninsurance_policy_lookup: Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\\ncalculator: Useful when you need to perform mathematical operations.\\n\\n\\n\\nUse the following format:\\n\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [cancel_policy_request, update_policy_request, insurance_policy_lookup, calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\n\\n\\nBegin!\\n\\nPrevious conversation history: Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought:\\nOriginal input: Update the insurance policy for Charles Wise by updating the phone number to 333-321-5622\\n\\nAssistant:\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   808.58 ms\n",
      "llama_print_timings:      sample time =    10.59 ms /    12 runs   (    0.88 ms per token,  1133.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2142.23 ms /    30 tokens (   71.41 ms per token,    14.00 tokens per second)\n",
      "llama_print_timings:        eval time =  1346.10 ms /    11 runs   (  122.37 ms per token,     8.17 tokens per second)\n",
      "llama_print_timings:       total time =  3534.29 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:LLMChain > 11:llm:Bedrock] [3.26s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Thought: Do I need to use a tool? Yes\\nAction: update_policy_request\\nAction Input: Submit a request to update the phone number in policy 54621 to 333-321-5622\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 10:chain:LLMChain] [3.26s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" Thought: Do I need to use a tool? Yes\\nAction: update_policy_request\\nAction Input: Submit a request to update the phone number in policy 54621 to 333-321-5622\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 12:tool:update_policy_request] Entering Tool run with input:\n",
      "\u001b[0m\"Submit a request to update the phone number in policy 54621 to 333-321-5622\"\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 12:tool:update_policy_request > 13:tool:update_policy_request] Entering Tool run with input:\n",
      "\u001b[0m\"Submit a request to update the phone number in policy 54621 to 333-321-5622\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 12:tool:update_policy_request > 13:tool:update_policy_request] [25ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Successfully submitted update for: 54621, Update for: phone, 333-321-5622, Status: 200 - {\"statusCode\": 200 }\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 12:tool:update_policy_request] [25ms] Exiting Tool run with output:\n",
      "\u001b[0m\"Successfully submitted update for: 54621, Update for: phone, 333-321-5622, Status: 200 - {\"statusCode\": 200 }\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Update the insurance policy for Charles Wise by updating the phone number to 333-321-5622\",\n",
      "  \"agent_scratchpad\": \" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought: Thought: Do I need to use a tool? Yes\\nAction: update_policy_request\\nAction Input: Submit a request to update the phone number in policy 54621 to 333-321-5622\\nObservation: Successfully submitted update for: 54621, Update for: phone, 333-321-5622, Status: 200 - {\\\"statusCode\\\": 200 }\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain > 15:llm:Bedrock] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent tasked with helping look up and modify insurance claims.\\n\\nGiven an input request, take a step-by-step approach to find an insurance policy and modify its status.\\nOnly use the tools provided.\\nWhen you have completed the task, end your chain of thought and provide a final response to the user.\\n\\nYou have access to the following tools:\\n\\ncancel_policy_request: Useful when you need to submit a request to cancel an insurance policy. This tool takes in the customer's policy id and will return an API response message. Example: [Submit a request to cancel policy for policy id of 4321]\\nupdate_policy_request: Useful when you need to submit a request to update an insurance policy. This tool takes in the customer's policy id to be updated as well as data to be updated. An API response will be returned.  Example: [Submit a request to update the phone number in policy 4321 to 455-255-5555]\\ninsurance_policy_lookup: Useful when you need to look up insurance policy information. This tool takes in a full question about customers and their policies and will return a policy id. Example: [What is the policy id for Jane Doe?, What is Cynthia Stone's policy?]\\ncalculator: Useful when you need to perform mathematical operations.\\n\\n\\n\\nUse the following format:\\n\\n\\nTo use a tool, please use the following format:\\n\\n```\\nThought: Do I need to use a tool? Yes\\nAction: the action to take, should be one of [cancel_policy_request, update_policy_request, insurance_policy_lookup, calculator]\\nAction Input: the input to the action\\nObservation: the result of the action\\n```\\n\\nWhen you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\\n\\n```\\nThought: Do I need to use a tool? No\\nFinal Answer: [your response here]\\n```\\n\\n\\n\\nBegin!\\n\\nPrevious conversation history: Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\\nObservation: The policy id is 54621.\\nThought: Thought: Do I need to use a tool? Yes\\nAction: update_policy_request\\nAction Input: Submit a request to update the phone number in policy 54621 to 333-321-5622\\nObservation: Successfully submitted update for: 54621, Update for: phone, 333-321-5622, Status: 200 - {\\\"statusCode\\\": 200 }\\nThought:\\nOriginal input: Update the insurance policy for Charles Wise by updating the phone number to 333-321-5622\\n\\nAssistant:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain > 15:llm:Bedrock] [5.13s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" Thought: Do I need to use a tool? No\\n\\nFinal Answer: I looked up Charles Wise's policy id using the insurance policy lookup tool and got id 54621. I then submitted a request using the update policy request tool to update the phone number in policy 54621 to 333-321-5622. The request was successful with a 200 response code. I have completed the original request to update Charles Wise's insurance policy phone number to 333-321-5622.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"Generation\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 14:chain:LLMChain] [5.13s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \" Thought: Do I need to use a tool? No\\n\\nFinal Answer: I looked up Charles Wise's policy id using the insurance policy lookup tool and got id 54621. I then submitted a request using the update policy request tool to update the phone number in policy 54621 to 333-321-5622. The request was successful with a 200 response code. I have completed the original request to update Charles Wise's insurance policy phone number to 333-321-5622.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [20.02s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Update the insurance policy for Charles Wise by updating the phone number to 333-321-5622',\n",
       " 'output': \"I looked up Charles Wise's policy id using the insurance policy lookup tool and got id 54621. I then submitted a request using the update policy request tool to update the phone number in policy 54621 to 333-321-5622. The request was successful with a 200 response code. I have completed the original request to update Charles Wise's insurance policy phone number to 333-321-5622.\",\n",
       " 'intermediate_steps': [(AgentAction(tool='insurance_policy_lookup', tool_input=\"What is Charles Wise's policy id?\", log=\" Thought: Do I need to use a tool? Yes\\nAction: insurance_policy_lookup \\nAction Input: What is Charles Wise's policy id?\"),\n",
       "   'The policy id is 54621.'),\n",
       "  (AgentAction(tool='update_policy_request', tool_input='Submit a request to update the phone number in policy 54621 to 333-321-5622', log=' Thought: Do I need to use a tool? Yes\\nAction: update_policy_request\\nAction Input: Submit a request to update the phone number in policy 54621 to 333-321-5622'),\n",
       "   'Successfully submitted update for: 54621, Update for: phone, 333-321-5622, Status: 200 - {\"statusCode\": 200 }')]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede685bc-2201-4409-b3e8-2d0ec742adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools( agent=agent, tools=tools, verbose=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb8be8-2b4b-403a-963a-fef843687965",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(query)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
